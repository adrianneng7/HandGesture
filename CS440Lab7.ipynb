{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Intelligence Spring 2019, Lab 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This program introduces the following concepts:\n",
    "\n",
    "*\t\ta) Reading a stream of images from a webcamera, and displaying the video (learned in lab 6)\n",
    "*\t\tb) Skin color detection (learned in lab 6)\n",
    "*\t\tc) Background differencing\n",
    "*\t\td) Visualizing motion history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from collections import deque\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# skin color detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that detects whether a pixel belongs to the skin based on RGB values\n",
    "# src - the source color image\n",
    "def mySkinDetect(src):\n",
    "    # Surveys of skin color modeling and detection techniques:\n",
    "    # 1. Vezhnevets, Vladimir, Vassili Sazonov, and Alla Andreeva. \"A survey on pixel-based skin color detection techniques.\" Proc. Graphicon. Vol. 3. 2003.\n",
    "    # 2. Kakumanu, Praveen, Sokratis Makrogiannis, and Nikolaos Bourbakis. \"A survey of skin-color modeling and detection methods.\" Pattern recognition 40.3 (2007): 1106-1122.\n",
    "    dst = np.zeros((src.shape[0], src.shape[1], 1), dtype = \"uint8\")\n",
    "    for i in range(src.shape[0]):\n",
    "        for j in range(src.shape[1]):\n",
    "            #b,g,r = src[i,j]\n",
    "            b = int(src[i,j][0])\n",
    "            g = int(src[i,j][1])\n",
    "            r = int(src[i,j][2])\n",
    "            if(r>45 and g>20 and b>5 and max(r,g,b)-min(r,g,b)>15 and abs(r-g)>15 and r>g and r>b):\n",
    "                dst[i,j] = 255\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# frame-to-frame differencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that does frame differencing between the current frame and the previous frame\n",
    "# prev - the previous color image\n",
    "# curr - the current color image\n",
    "# dst - the destination grayscale image where pixels are colored white if the corresponding pixel intensities in the current\n",
    "# and previous image are not the same\n",
    "def myFrameDifferencing(prev, curr):\n",
    "    # For more information on operation with arrays: \n",
    "    # http://docs.opencv.org/modules/core/doc/operations_on_arrays.html\n",
    "    \n",
    "    \n",
    "    \n",
    "    #dst = np.zeros((prev.shape[0], prev.shape[1], 1), dtype = \"uint8\")\n",
    "    dst = cv2.absdiff(prev,curr)\n",
    "    dst = cv2.cvtColor(dst, cv2.COLOR_BGR2GRAY) #convert color image to gray scale image\n",
    "    _, dst = cv2.threshold(dst, 50, 255, cv2.THRESH_BINARY) #if pixel is greater than 50, set the pixel to white (only get the second value)\n",
    "                \n",
    "            \n",
    "    return dst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# motion energy templates\n",
    "* example 1: the bottom row displays a cumulative binary motion energy image sequence corresponding to the frames above\n",
    "![title](mh1.png)\n",
    "* example 2: pixel intensity is a function of the motion history at that location, where brighter values correspond to more recent motion, three actions: sit-down, arms-raise, crouch-down\n",
    "![title](mh2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that accumulates the frame differences for a certain number of pairs of frames\n",
    "# mh - vector of frame difference images\n",
    "# dst - the destination grayscale image to store the accumulation of the frame difference images\n",
    "def myMotionEnergy(mh):\n",
    "    # the window of time is 3\n",
    "    mh0 = mh[0]\n",
    "    mh1 = mh[1]\n",
    "    mh2 = mh[2]\n",
    "    dst = np.zeros((mh0.shape[0], mh0.shape[1], 1), dtype = \"uint8\")\n",
    "    for i in range(mh0.shape[0]):\n",
    "        for j in range(mh0.shape[1]):\n",
    "            if mh0[i,j] == 255 or mh1[i,j] == 255 or mh2[i,j] == 255:\n",
    "                dst[i,j] = 255\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manualtemplatematch(curr):\n",
    "    img = myMotionEnergy(curr)\n",
    "    template = cv2.imread('template.png',0)\n",
    "    ret,dst = cv2.threshold(template,127,255,cv2.THRESH_BINARY)\n",
    "    templateresized = cv2.resize(dst, (curr.shape[0], curr.shape[1]))\n",
    "    n = 0\n",
    "    #print(img.shape)\n",
    "    #print(templateresized.shape)\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            if img[i,j] == templateresized[i,j]:\n",
    "                n +=1\n",
    "    if n/22500 >=.0065:\n",
    "        return True\n",
    "    return False\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment(src, threshold = 50):\n",
    "    global bg \n",
    "    diff = cv2.absdiff(bg.astype(\"uint8\"),src)\n",
    "    thresholded = cv2.threshold(diff,threshold,255,cv2.THRESH_BINARY)[1]\n",
    "    (_,cnts, _) = cv2.findContours(mySkinDetect(src), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if len(cnts)==0:\n",
    "        return\n",
    "    else:\n",
    "        segmented = max(cnts, key=cv2.contourArea)\n",
    "        x, y, w, h = cv2.boundingRect(segmented)\n",
    "        cv2.rectangle(src, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        return (cv2.drawContours(src, segmented, -1, (255, 255, 0), 1))\n",
    "        #return (thresholded, segmented)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boundingBox(curr):\n",
    "    \n",
    "    (_,cnts, _) = cv2.findContours(mySkinDetect(curr), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if len(cnts)==0:\n",
    "        return\n",
    "    else:\n",
    "        segmented = max(cnts, key=cv2.contourArea)\n",
    "        return segmented\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(curr, segmented):\n",
    "    #fnd the convex hull of the segmented hand region\n",
    "    chull = cv2.convexHull(segmented)\n",
    "    thresholded = mySkinDetect(curr)\n",
    "    # find the most extreme points in the convex hull\n",
    "    extreme_top    = tuple(chull[chull[:, :, 1].argmin()][0])\n",
    "    extreme_bottom = tuple(chull[chull[:, :, 1].argmax()][0])\n",
    "    extreme_left   = tuple(chull[chull[:, :, 0].argmin()][0])\n",
    "    extreme_right  = tuple(chull[chull[:, :, 0].argmax()][0])\n",
    "    \n",
    "\n",
    "    # find the center of the palm\n",
    "    cX = (extreme_left[0] + extreme_right[0]) / 2\n",
    "    cY = (extreme_top[1] + extreme_bottom[1]) / 2\n",
    "    dist1 = ((cX-extreme_left[0])**2 + (cY-extreme_left[1])**2)**0.5\n",
    "    dist2 = ((cX-extreme_right[0])**2 + (cY-extreme_right[1])**2)**0.5\n",
    "    dist3 = ((cX-extreme_top[0])**2 + (cY-extreme_top[1])**2)**0.5\n",
    "    dist4 = ((cX-extreme_bottom[0])**2 + (cY-extreme_bottom[1])**2)**0.5\n",
    "    # find the maximum euclidean distance between the center of the palm\n",
    "    # and the most extreme points of the convex hull\n",
    "    x = np.array([(cX,cY)])\n",
    "    y = np.array([extreme_left, extreme_right, extreme_top, extreme_bottom])\n",
    "    \n",
    "    distance = np.array ([[dist1], [dist2], [dist3], [dist4]])[0]\n",
    "    maximum_distance = distance[distance.argmax()]\n",
    "    \n",
    "    # calculate the radius of the circle with 80% of the max euclidean distance obtained\n",
    "    radius = int(0.8 * maximum_distance)\n",
    "    \n",
    "    # find the circumference of the circle\n",
    "    circumference = (2 * np.pi * radius)\n",
    "\n",
    "    # take out the circular region of interest which has \n",
    "# the palm and the fingers\n",
    "    circular_roi = np.zeros(thresholded.shape[:2], dtype=\"uint8\")\n",
    "    # draw the circular ROI\n",
    "    cv2.circle(circular_roi, (int(cX), int(cY)), int(radius), 255, 1)\n",
    "    \n",
    "\n",
    "\t# take bit-wise AND between thresholded hand using the circular ROI as the mask\n",
    "\t# which gives the cuts obtained using mask on the thresholded hand image\n",
    "    circular_roi = cv2.bitwise_and(thresholded, thresholded, mask=circular_roi)\n",
    "\n",
    "\t# compute the contours in the circular ROI\n",
    "    (_, cnts, _) = cv2.findContours(circular_roi.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "\t# initalize the finger count\n",
    "    count = 0\n",
    "\n",
    "\t# loop through the contours found\n",
    "    for c in cnts:\n",
    "\t\t# compute the bounding box of the contour\n",
    "        (x, y, w, h) = cv2.boundingRect(c)\n",
    "\n",
    "\t\t# increment the count of fingers only if -\n",
    "\t\t# 1. The contour region is not the wrist (bottom area)\n",
    "\t\t# 2. The number of points along the contour does not exceed\n",
    "\t\t#     25% of the circumference of the circular ROI\n",
    "        if ((cY + (cY * 0.25)) > (y + h)) and ((circumference * 0.25) > c.shape[0]):\n",
    "            count += 1\n",
    "    if (manualtemplatematch(curr)) == True:\n",
    "        return (\"Waving\")\n",
    "    else:\n",
    "        if count == 2: \n",
    "            return (\"Scissor\")\n",
    "        if count >=4 :\n",
    "            return (\"Paper\")\n",
    "        if count <=1:\n",
    "            return (\"Rock\")\n",
    "    return (\"No Gesture Detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # a) Reading a stream of images from a webcamera, and displaying the video\n",
    "    # open the video camera no. 0/modules/highgui/doc/reading_and_writing_images_and_video.html\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    #if not successful, exit program\n",
    "    if not cap.isOpened():\n",
    "        print(\"Cannot open the video cam\")\n",
    "        return -1\n",
    "\n",
    "    # read a new frame from video\n",
    "    success, prev_frame = cap.read()\n",
    "    \n",
    "    #if not successful, exit program\n",
    "    if not success:\n",
    "        print(\"Cannot read a frame from video stream\")\n",
    "        return -1\n",
    "    cv2.namedWindow(\"frame\", cv2.WINDOW_AUTOSIZE)\n",
    "    \n",
    "    prev_frame = cv2.resize(prev_frame,(150,150))\n",
    "    fMH1 = np.zeros((prev_frame.shape[0], prev_frame.shape[1], 1), dtype = \"uint8\")\n",
    "    fMH2 = fMH1.copy()\n",
    "    fMH3 = fMH1.copy()\n",
    "    myMotionHistory = deque([fMH1, fMH2, fMH3])\n",
    "\n",
    "    \n",
    "    while(True):\n",
    "        #read a new frame from video\n",
    "        success, curr_frame = cap.read()\n",
    "        curr_frame = cv2.resize(curr_frame,(150,150))\n",
    "        \n",
    "        if not success:\n",
    "            print(\"Cannot read a frame from video stream\")\n",
    "            break\n",
    "        curr_frame = cv2.flip(curr_frame,1)\n",
    "  \n",
    "\n",
    "        cv2.imshow('frame',curr_frame)\n",
    "\n",
    "        # b) Skin color detection\n",
    "        mySkin = mySkinDetect(curr_frame)\n",
    "        cv2.imshow('mySkinDetect',mySkin)\n",
    "\n",
    "        #Background differencing\n",
    "        #bd = backgroundDifferencing(curr_frame)\n",
    "        #cv2.imshow('myBackgroundDifferencing', bd)\n",
    "        \n",
    "        # c) Frame by frame differencing\n",
    "        #frameDest = myFrameDifferencing(prev_frame, curr_frame)\n",
    "        #cv2.imshow('myFrameDifferencing',frameDest)\n",
    "        \n",
    "        #myMotionHistory.popleft()\n",
    "        #myMotionHistory.append(frameDest)\n",
    "        #myMH = myMotionEnergy(myMotionHistory)\n",
    "        #cv2.imshow('myMotionHistory',myMH)\n",
    "\n",
    "        prev_frame = curr_frame\n",
    "        \n",
    "         #template matching\n",
    "        #tm = templateMatching2(curr_frame)\n",
    "        #cv2.imshow('templateMatching', tm)\n",
    "        \n",
    "        #bounding box\n",
    "        segmented = boundingBox(curr_frame)\n",
    "        x, y, w, h = cv2.boundingRect(segmented)\n",
    "        bound = cv2.rectangle(curr_frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        bound =(cv2.drawContours(curr_frame, segmented, -1, (255, 255, 0), 1))\n",
    "        \n",
    "        \n",
    "        fingers = count(curr_frame, segmented)\n",
    "     \n",
    "        bound = cv2.putText(curr_frame, str(fingers), (70, 45), cv2.FONT_HERSHEY_SIMPLEX, .5, (0,0,255), 2)\n",
    "        cv2.imshow('myBoundingBox', bound)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # wait for 'q' key press. If 'q' key is pressed, break loop\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.1) C:\\Miniconda3\\conda-bld\\opencv-suite_1533128839831\\work\\modules\\imgproc\\src\\convhull.cpp:137: error: (-215) total >= 0 && (depth == 5 || depth == 4) in function cv::convexHull\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-187-972361fa1b80>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-186-dba0096c3852>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m         \u001b[0mfingers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurr_frame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msegmented\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[0mbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mputText\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurr_frame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfingers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m70\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m45\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFONT_HERSHEY_SIMPLEX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-184-ed1fef139650>\u001b[0m in \u001b[0;36mcount\u001b[1;34m(curr, segmented)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msegmented\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;31m#fnd the convex hull of the segmented hand region\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mchull\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvexHull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msegmented\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mthresholded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmySkinDetect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# find the most extreme points in the convex hull\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(3.4.1) C:\\Miniconda3\\conda-bld\\opencv-suite_1533128839831\\work\\modules\\imgproc\\src\\convhull.cpp:137: error: (-215) total >= 0 && (depth == 5 || depth == 4) in function cv::convexHull\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
